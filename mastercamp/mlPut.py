import spacy
import pytextrank
from transformers import PegasusForConditionalGeneration, PegasusTokenizer
from transformers import pipeline
import sys
args = sys.argv

# print(1)
# event_first_player = args[0]
# event_second_player = args[1]
# event_final_result = args[2]
# event_winner = args[3]
# scores = args[4]
# event_date = args[5]
# tournament_name = args[6]

# Load the large English language model
nlp = spacy.load("en_core_web_lg")

# Add TextRank algorithm to the pipeline
nlp.add_pipe("textrank")

texte = """Lors de la compétition de tennis {tournament_name}, un affrontement palpitant a eu lieu entre deux joueurs talentueux, {event_first_player} et {event_second_player}. Ce match a été le théâtre d'un spectacle captivant, offrant des moments de tension, d'excitation et de brillantes démonstrations de jeu. Plongeons dans les temps forts de cette rencontre épique qui a tenu en haleine les fans de tennis.
Les deux protagonistes, {event_first_player} et {event_second_player}, ont abordé ce match avec détermination et ambition. Ils étaient tous deux déterminés à prouver leur valeur sur le court de {tournament_name}, attirant ainsi l'attention des amateurs de tennis du monde entier.
Le premier set a immédiatement captivé l'attention des spectateurs. Les échanges étaient intenses, avec des coups précis et des déplacements rapides. {event_first_player} et {event_second_player} se sont livrés à une bataille sans merci, essayant de prendre le dessus sur l'autre. Finalement, après une lutte acharnée, {scores} a été en faveur de {event_winner}.
Le deuxième set a été tout aussi captivant. Les deux joueurs ont continué à s'affronter avec une grande intensité, cherchant à exploiter les faiblesses de leur adversaire. Les échanges étaient riches en stratégie, avec des variations de rythme et des coups puissants. Ce set s'est conclu avec un scores de {scores} en faveur de {event_winner}.
Au fur et à mesure que le match progressait, la tension montait sur le court. Les spectateurs étaient suspendus à chaque coup, admirant le talent et la ténacité des deux joueurs. Chaque point était crucial, et la lutte pour la victoire était plus intense que jamais.
Le troisième set a été le tournant décisif du match."""

# /* Les deux joueurs se sont surpassés, affichant une détermination sans faille. Les échanges étaient spectaculaires, avec des coups gagnants et des défenses impressionnantes. Le scores était serré tout au long du set, créant une atmosphère électrique sur le court.
# Finalement, après une bataille acharnée, {event_winner} a réussi à prendre l'avantage et à remporter le set avec un scores de {scores}. Cette victoire a propulsé {event_winner} vers la ligne d'arrivée, mais {event_second_player/event_first_player} ne s'est pas laissé abattre et a continué à se battre jusqu'au dernier point.
# Ce match de tennis passionnant entre {event_first_player} et {event_second_player} à {tournament_name} a été un véritable spectacle sportif. Les deux joueurs ont montré leur talent, leur endurance et leur esprit combatif tout au long de la rencontre. Ce match restera dans les mémoires comme un exemple de la beauté du tennis et de la rivalité saine entre les athlètes.
# Que vous soyez un passionné de tennis ou un amateur de sports en général, ce duel inoubliable entre {event_first_player} et {event_second_player} à {tournament_name} vous a offert des moments de pur plaisir et d'excitation. Il témoigne de l'attrait universel de ce sport, capable de nous transporter et de nous faire vibrer à chaque échange.*/

# Execute the Spacy pipeline with the TextRank algorithm
doc = nlp(texte)

# Print the summary generated by TextRank
# for sent in doc._.textrank.summary(limit_phrases=50, limit_sentences=50):
#     print(sent)

# Pick the Pegasus model
model_name = "google/pegasus-xsum"

# Load the pretrained tokenizer
pegasus_tokenizer = PegasusTokenizer.from_pretrained(model_name)

# Define the Pegasus model
pegasus_model = PegasusForConditionalGeneration.from_pretrained(model_name)

# Create tokens for the Pegasus model
tokens = pegasus_tokenizer(texte, truncation=True,
                           padding="longest", return_tensors="pt")

# Generate the summary using Pegasus
# Adjust max_length to get a shorter summary
encoded_summary = pegasus_model.generate(
    **tokens, max_length=200, do_sample=True, temperature=1.5)

# Decode the summarized text
decoded_summary = pegasus_tokenizer.decode(
    encoded_summary[0], skip_special_tokens=True)

# print("\n Petit résumé :\n")
print(decoded_summary)

# Define the pipeline for the summary
summarizer = pipeline(
    "summarization",
    model=model_name,
    tokenizer=pegasus_tokenizer,
    framework="pt"
)

# Create a shorter summary using the pipeline
summary = summarizer(texte, min_length=50, max_length=200,
                     do_sample=True, temperature=1.5)

print("\n Grand résumé :\n")
print(summary[0]["summary_text"])
